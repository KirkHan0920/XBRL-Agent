{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","mount_file_id":"1gNjNk_Yp5L7fx-U43_OEjOk9mQRv31HS","authorship_tag":"ABX9TyPc5o5jacMqfk7CEG5BDLSP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0rS_dEqRCJqj"},"outputs":[],"source":["from transformers import AutoTokenizer, BitsAndBytesConfig, pipeline, AutoModelForCausalLM\n","import torch\n","import json\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["from huggingface_hub import login\n","hf_api_key = \"\"\n","login(hf_api_key)"],"metadata":{"id":"dpme6mXngwMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"EAb5oKR9gxcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir(\"\")"],"metadata":{"id":"TqLvXiR7AJr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = 'XBRL Terminology.xlsx'\n","df_all = pd.read_excel(file_path)"],"metadata":{"id":"uLEpAVFXBJn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df_all[:500]"],"metadata":{"id":"eEIfbBrnuKPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\").to(device)\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n","print(\"load done!\")"],"metadata":{"id":"zijvY3I9guMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_title = pd.DataFrame(columns=['Term', 'Generated Explanation'])\n","excel_path = 'xbrl_terms_explanations_llama3_7b_500.xlsx'\n","df_title.to_excel(excel_path, index=False)"],"metadata":{"id":"aAv6ahOfXJLN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["terms = df['Term'].tolist()\n","\n","prompt = \"You are an expert in the financial field with deep expertise in the eXtensible Business Reporting Language (XBRL) standard. Please provide detailed explanations of the following XBRL terms: \"\n","\n","generated_explanations = []\n","for i, term in enumerate(terms):\n","    input_text = prompt + term\n","    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","                {\"role\": \"user\", \"content\": input_text}]\n","    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n","\n","    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=256)\n","    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n","    explanation = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    generated_explanations.append(explanation)\n","    print(f\"{i} + {explanation}\")\n","\n","    new_row = pd.DataFrame({'Term': [term], 'Explanation': [explanation]})\n","\n","    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n","        book = writer.book\n","        startrow = writer.sheets['Sheet1'].max_row\n","        new_row.to_excel(writer, index=False, header=False, startrow=startrow)\n","    print(f\"{i}\" + \" saved\")\n","\n","print(\"finished\")"],"metadata":{"id":"zR7l8SeRgqry"},"execution_count":null,"outputs":[]}]}